cmake_minimum_required(VERSION 3.18)

# CUDA 12.8 호환 아키텍처 설정 (컴파일러 식별 이전에 설정)
set(CMAKE_CUDA_ARCHITECTURES "75;86;89")
# CUDA 컴파일러 식별 단계에서 deprecated 경고 억제
set(CMAKE_CUDA_FLAGS "-Wno-deprecated-gpu-targets")

project(reality_stone LANGUAGES CXX)

# CUDA 옵션
option(USE_CUDA "Enable CUDA support" ON)

# CUDA 지원 확인 및 활성화 (개선된 방법)
if(USE_CUDA)
    include(CheckLanguage)
    
    # 먼저 CUDA 환경 변수 확인
    if(DEFINED ENV{CUDA_PATH})
        set(CMAKE_CUDA_COMPILER "$ENV{CUDA_PATH}/bin/nvcc.exe")
        message(STATUS "Using CUDA from environment: $ENV{CUDA_PATH}")
    elseif(DEFINED ENV{CUDA_HOME})
        set(CMAKE_CUDA_COMPILER "$ENV{CUDA_HOME}/bin/nvcc.exe")
        message(STATUS "Using CUDA from CUDA_HOME: $ENV{CUDA_HOME}")
    endif()
    
    check_language(CUDA)
    if(CMAKE_CUDA_COMPILER)
        message(STATUS "Attempting to enable CUDA...")
        enable_language(CUDA OPTIONAL)
        if(CMAKE_CUDA_COMPILER_ID)
            set(CUDA_ENABLED TRUE)
            message(STATUS "CUDA found: ${CMAKE_CUDA_COMPILER}")
            message(STATUS "CUDA architectures: ${CMAKE_CUDA_ARCHITECTURES}")
        else()
            set(CUDA_ENABLED FALSE)
            message(WARNING "CUDA compiler detected but failed to initialize - building CPU-only version")
        endif()
    else()
        set(CUDA_ENABLED FALSE)
        message(STATUS "CUDA not found, building CPU-only version")
    endif()
else()
    set(CUDA_ENABLED FALSE)
    message(STATUS "CUDA disabled by user - building CPU-only version")
endif()

# Python 찾기
find_package(Python 3.8 REQUIRED COMPONENTS Interpreter Development)

# Get python executable path
if(Python_EXECUTABLE)
    set(PYTHON_EXE "${Python_EXECUTABLE}")
else()
    set(PYTHON_EXE "${Python_INTERPRETER}")
endif()

# pybind11 찾기 (개선된 방법)
execute_process(
    COMMAND "${PYTHON_EXE}" -m pybind11 --cmakedir
    OUTPUT_VARIABLE PYBIND11_CMAKE_DIR
    OUTPUT_STRIP_TRAILING_WHITESPACE
    RESULT_VARIABLE PYBIND11_RESULT
)

if(PYBIND11_RESULT EQUAL 0 AND PYBIND11_CMAKE_DIR)
    file(TO_CMAKE_PATH "${PYBIND11_CMAKE_DIR}" PYBIND11_CMAKE_DIR_FIXED)
    list(APPEND CMAKE_MODULE_PATH "${PYBIND11_CMAKE_DIR_FIXED}")
    find_package(pybind11 REQUIRED)
    message(STATUS "pybind11 found: ${PYBIND11_CMAKE_DIR}")
else()
    # Fallback: try to find pybind11 directly
    find_package(pybind11 QUIET)
    if(NOT pybind11_FOUND)
        message(FATAL_ERROR "pybind11 not found. Install with: pip install pybind11")
    endif()
endif()

# PyTorch 찾기 (개선된 방법 - 충돌 방지)
execute_process(
    COMMAND "${PYTHON_EXE}" -c "import sys, os; os.chdir(os.path.expanduser('~')); import torch; print(torch.utils.cmake_prefix_path)"
    OUTPUT_VARIABLE TORCH_CMAKE_DIR
    OUTPUT_STRIP_TRAILING_WHITESPACE
    RESULT_VARIABLE TORCH_RESULT
    ERROR_QUIET
)

if(TORCH_RESULT EQUAL 0 AND TORCH_CMAKE_DIR)
    file(TO_CMAKE_PATH "${TORCH_CMAKE_DIR}" TORCH_CMAKE_DIR_FIXED)
    list(APPEND CMAKE_PREFIX_PATH "${TORCH_CMAKE_DIR_FIXED}")
    find_package(Torch REQUIRED)
    message(STATUS "PyTorch found: ${TORCH_VERSION}")
else()
    # Fallback: try direct torch discovery from home directory
    execute_process(
        COMMAND "${PYTHON_EXE}" -c "import sys, os; os.chdir(os.path.expanduser('~')); import torch; print(torch.__path__[0])"
        OUTPUT_VARIABLE TORCH_PATH
        OUTPUT_STRIP_TRAILING_WHITESPACE
        RESULT_VARIABLE TORCH_PATH_RESULT
        ERROR_QUIET
    )
    
    if(TORCH_PATH_RESULT EQUAL 0 AND TORCH_PATH)
        # Try to find torch in the torch installation directory
        set(CMAKE_PREFIX_PATH "${TORCH_PATH}/share/cmake/Torch;${CMAKE_PREFIX_PATH}")
        find_package(Torch QUIET)
        
        if(Torch_FOUND)
            message(STATUS "PyTorch found via fallback method")
        else()
            message(WARNING "PyTorch found but CMake config not available, proceeding without CMake integration")
            # Set basic torch variables manually
            execute_process(
                COMMAND "${PYTHON_EXE}" -c "import sys, os; os.chdir(os.path.expanduser('~')); import torch; print(';'.join(torch.utils.cpp_extension.include_paths()))"
                OUTPUT_VARIABLE TORCH_INCLUDE_DIRS
                OUTPUT_STRIP_TRAILING_WHITESPACE
                ERROR_QUIET
            )
            execute_process(
                COMMAND "${PYTHON_EXE}" -c "import sys, os; os.chdir(os.path.expanduser('~')); import torch; print(';'.join(torch.utils.cpp_extension.library_paths()))"
                OUTPUT_VARIABLE TORCH_LIBRARY_DIRS
                OUTPUT_STRIP_TRAILING_WHITESPACE
                ERROR_QUIET
            )
            if(TORCH_INCLUDE_DIRS)
                message(STATUS "Using manual PyTorch configuration")
                set(TORCH_FOUND TRUE)
            else()
                message(FATAL_ERROR "PyTorch not found. Install with: pip install torch")
            endif()
        endif()
    else()
        message(FATAL_ERROR "PyTorch not found. Install with: pip install torch")
    endif()
endif()

# 소스 파일 수집
file(GLOB_RECURSE CPP_SOURCES "src/*.cpp")
if(CUDA_ENABLED)
    file(GLOB_RECURSE CUDA_SOURCES "src/*.cu")
    set(ALL_SOURCES ${CPP_SOURCES} ${CUDA_SOURCES})
else()
    set(ALL_SOURCES ${CPP_SOURCES})
endif()

# 모듈 생성
pybind11_add_module(_C SHARED ${ALL_SOURCES})

# 인클루드 디렉토리
target_include_directories(_C PRIVATE
    "${PROJECT_SOURCE_DIR}/src/include"
    "${PROJECT_SOURCE_DIR}/src/core"
)

# PyTorch 인클루드를 시스템 헤더로 처리하여 경고 억제
if(DEFINED TORCH_INCLUDE_DIRS)
    target_include_directories(_C SYSTEM PRIVATE
        "${TORCH_INCLUDE_DIRS}"
    )
else()
    # Try to get include directories manually if CMake config failed
    execute_process(
        COMMAND "${PYTHON_EXE}" -c "import sys, os; os.chdir(os.path.expanduser('~')); import torch; print(';'.join(torch.utils.cpp_extension.include_paths()))"
        OUTPUT_VARIABLE MANUAL_TORCH_INCLUDES
        OUTPUT_STRIP_TRAILING_WHITESPACE
        ERROR_QUIET
    )
    if(MANUAL_TORCH_INCLUDES)
        target_include_directories(_C SYSTEM PRIVATE
            "${MANUAL_TORCH_INCLUDES}"
        )
        message(STATUS "Using manual PyTorch includes: ${MANUAL_TORCH_INCLUDES}")
    endif()
endif()

# CUDA include 경로를 시스템 헤더로 처리
if(CUDA_ENABLED)
    target_include_directories(_C SYSTEM PRIVATE
        "${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES}"
    )
endif()

# C++ 표준 설정
set_target_properties(_C PROPERTIES 
    CXX_STANDARD 17
    CXX_STANDARD_REQUIRED ON
    CXX_EXTENSIONS OFF
)

# CUDA 설정 (활성화된 경우만) - NVCC 오류 해결
if(CUDA_ENABLED)
    set_target_properties(_C PROPERTIES 
        CUDA_STANDARD 17
        CUDA_STANDARD_REQUIRED ON
        CUDA_EXTENSIONS OFF
        CUDA_SEPARABLE_COMPILATION OFF  # NVCC 오류 해결을 위해 OFF로 설정
    )
    # WITH_CUDA 매크로 정의
    target_compile_definitions(_C PRIVATE WITH_CUDA)
endif()

# 컴파일러별 최적화 설정
if(MSVC)
    # Windows/MSVC 최적화 (C++ 파일만)
    target_compile_options(_C PRIVATE
        $<$<COMPILE_LANGUAGE:CXX>:/O2>          # 최적화
        $<$<COMPILE_LANGUAGE:CXX>:/Ob2>         # 인라인 확장
        $<$<COMPILE_LANGUAGE:CXX>:/MP>          # 멀티프로세서 컴파일
        $<$<COMPILE_LANGUAGE:CXX>:/bigobj>      # 큰 객체 파일 지원
        $<$<COMPILE_LANGUAGE:CXX>:/EHsc>        # 예외 처리
        $<$<COMPILE_LANGUAGE:CXX>:/wd4819>      # 경고 무시 - 코드 페이지
        $<$<COMPILE_LANGUAGE:CXX>:/wd4251>      # DLL 인터페이스 경고
        $<$<COMPILE_LANGUAGE:CXX>:/wd4244>      # 타입 변환 경고
        $<$<COMPILE_LANGUAGE:CXX>:/wd4267>      # 크기 변환 경고
        $<$<COMPILE_LANGUAGE:CXX>:/wd4275>      # DLL 베이스 클래스 경고
        $<$<COMPILE_LANGUAGE:CXX>:/wd4018>      # 부호 있음/없음 비교
        $<$<COMPILE_LANGUAGE:CXX>:/wd4190>      # C 링크 경고
        $<$<COMPILE_LANGUAGE:CXX>:/wd4624>      # 소멸자 경고
        $<$<COMPILE_LANGUAGE:CXX>:/wd1394>      # PyTorch DLL 인터페이스 경고
        $<$<COMPILE_LANGUAGE:CXX>:/wd1388>      # DLL export/import 경고
        $<$<COMPILE_LANGUAGE:CXX>:/WX->         # 경고를 에러로 처리하지 않음
        $<$<COMPILE_LANGUAGE:CXX>:/external:W0> # 외부 헤더 경고 완전 억제
    )
    
    if(CUDA_ENABLED)
        # CUDA 전용 플래그 - NVCC 호환성 개선
        target_compile_options(_C PRIVATE
            $<$<COMPILE_LANGUAGE:CUDA>:-O3>
            $<$<COMPILE_LANGUAGE:CUDA>:--use_fast_math>
            $<$<COMPILE_LANGUAGE:CUDA>:-Xcompiler=/O2>
            $<$<COMPILE_LANGUAGE:CUDA>:-Xcompiler=/EHsc>
            $<$<COMPILE_LANGUAGE:CUDA>:-w>  # CUDA 경고 비활성화
            $<$<COMPILE_LANGUAGE:CUDA>:-Xcompiler=/w>  # 호스트 컴파일러 경고 비활성화
        )
    endif()
    
    # 링크 타임 최적화 (C++만)
    set_target_properties(_C PROPERTIES
        INTERPROCEDURAL_OPTIMIZATION TRUE
    )
    
else()
    # GCC/Clang 최적화
    target_compile_options(_C PRIVATE
        -O3                    # 최고 최적화
        -march=native          # 현재 CPU에 최적화
        -mtune=native          # 현재 CPU에 맞춤
        -ffast-math           # 빠른 수학 연산
        -funroll-loops        # 루프 언롤링
    )
    
    if(CUDA_ENABLED)
        target_compile_options(_C PRIVATE
            $<$<COMPILE_LANGUAGE:CUDA>:-O3>
            $<$<COMPILE_LANGUAGE:CUDA>:--use_fast_math>
        )
    endif()
    
    # 링크 타임 최적화
    if(NOT CMAKE_BUILD_TYPE STREQUAL "Debug")
        set_target_properties(_C PROPERTIES
            INTERPROCEDURAL_OPTIMIZATION TRUE
        )
        target_link_options(_C PRIVATE
            -flto              # 링크 타임 최적화
            -Wl,--strip-all    # 심볼 제거
        )
    endif()
endif()

# PyTorch 라이브러리 링크
if(DEFINED TORCH_LIBRARIES)
    target_link_libraries(_C PRIVATE ${TORCH_LIBRARIES})
else()
    # Manual linking for PyTorch
    if(TORCH_LIBRARY_DIRS)
        target_link_directories(_C PRIVATE ${TORCH_LIBRARY_DIRS})
    endif()
    target_link_libraries(_C PRIVATE torch torch_cpu)
endif()

# PyTorch Python extension 지원을 위한 라이브러리 추가
execute_process(
    COMMAND "${PYTHON_EXE}" -c "import sys, os; os.chdir(os.path.expanduser('~')); import torch; print(os.path.join(os.path.dirname(torch.__file__), 'lib'))"
    OUTPUT_VARIABLE TORCH_LIB_PATH
    OUTPUT_STRIP_TRAILING_WHITESPACE
    ERROR_QUIET
)

if(TORCH_LIB_PATH AND EXISTS "${TORCH_LIB_PATH}/torch_python.lib")
    target_link_libraries(_C PRIVATE "${TORCH_LIB_PATH}/torch_python.lib")
    message(STATUS "Found torch_python.lib: ${TORCH_LIB_PATH}/torch_python.lib")
elseif(EXISTS "${CMAKE_PREFIX_PATH}/torch/lib/torch_python.lib")
    target_link_libraries(_C PRIVATE torch_python)
elseif(DEFINED TORCH_INCLUDE_DIRS)
    # PyTorch 경로에서 torch_python.lib 직접 찾기
    string(REPLACE "/include" "/lib" TORCH_LIB_DIR "${TORCH_INCLUDE_DIRS}")
    if(EXISTS "${TORCH_LIB_DIR}/torch_python.lib")
        target_link_libraries(_C PRIVATE "${TORCH_LIB_DIR}/torch_python.lib")
    endif()
endif()

# CUDA 런타임 링크 (필요시)
if(CUDA_ENABLED AND DEFINED TORCH_CUDA_LIBRARIES)
    target_link_libraries(_C PRIVATE ${TORCH_CUDA_LIBRARIES})
endif()

# 설치
install(TARGETS _C DESTINATION "reality_stone")